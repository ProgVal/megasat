=== Rendu 2 ===
Pleins de jolies petites fonctionnalités !

Au menu :
- Les heuristiques sur son lit d'injection de dépendances et de foire aux options
- Les formules logiques générales à la sauce transformations de Tseitin
- Les graphes recouverts d'un fin coulis de coloriage
- La corbeille de tests

Tout d'abord une option "-v" (comme verbose) a été ajoutée pour afficher des données sur le calcul courant (choix de l'heuristique, formule en forme normale conjonctive pour la résolution d'une formule générale...).

Pour les heuristiques elles sont chacune implémentées dans une classe séparée implémentant dans même interface VariableNonAssigneeProvider puis injectées à la construction du solveur.
Les heuristiques disponibles sont :
- simple : la première variable non assignée trouvée en l'assignant à true en premier (option -simple)
- rand : une variable libre prise au hasard en l'assignant à true en premier (option -rand)
- malin : une variable libre prise au hasard en l'assignant à la polarité la plus présente dans les clauses (option -malin)
- MOMS : heuristique MOMS (option -moms)
- DLIS : heuristique DLIS (option -dlis)
On rappelle que les trois algorithmes de résolutions sont :
- DPLL simple (option -dpll)
- DPLL avec Watched Literals (option -wl)
- Davis-Putnam (option -dp, n'utilise pas les heuristiques)
Les options de choix de système de résolution et d'heuristique sont disponibles pour les 3 exécutables (resol, tseitin et colorie).

Les formules logiques générales on eu droit à leur parseur fait avec Flex et GNU Bison (code dans /logique_parser). Elle sont représentées par un arbre de FormuleTseitin. On a préféré ne pas utiliser d'héritage ici pour éviter de nombreux cast dans les transformations.
La transformation de Tseitin est exécutée, suivant la spécification, par TransformationTseitin qui fournis une table de correspondance entre les noms de variables dans la formule vers les identifiants numériques utilisés par la structure de données Formule.
L'exécution du SAT-solveur se fait comme d'habitude, puis la table de correspondance est utilisée pour la sortie.

Pour utiliser le solveur de formule logique, il suffit de passer la formule dans un fichier à l'exécutable "tseitin" :
   ./tseitin exemple.txt

Pour les graphes, un petit parseur se charge de créer une structure de donnée Graphe sans grand intérêt (les graphes sont codés par la liste de arêtes).
Ensuite, CreateurContraintesColoriage se charge de crée une formule représentant les contraintes de coloriages.
Soit k le nombre de couleurs, codés sur log2(k) bits pour chaque sommets et n le nombre d'arêtes.
On a n*log2(n) variables "i j" codant le j ème bit de la couleur du sommet i.
Les contraintes sont :
- Que pour chaque arêtes (i,j), les couleurs soient différentes, i.e. qu'il existe un bit différent donc que (("i 0" xor "j 0") ou .. ou ("i log2(k)" xor "j log2(k)")) soit vrai.
- Que la couleur des sommets s soient < k (on les codes de 0 à k-1). On note k = k_l...k_0 en base 2. On construit la contraintes par récurrence avec contrainte(s,i) la contrainte en supposant que les bits (i+1)...l de la couleur et de k sont égaux.
  Initialisation : contrainte(s,0) = false (il faut que la couleur soit strictement inférieure à k)
  Récurrence :
    - si k_i = 1 alors on a contrainte(s,i) = non("s i") ou contraintes(s, i-1) (si le i ème bit est à 0 c'est bon, sinon les bits i..l sont identiques).
    - si k_i = 0 alors contraintes contrainte(s,i) = non("s i") et contraintes(s, i-1) (il ne faut pas que le i ème bit soit à 1 et on a les bits i..l identiques).
Ensuite, on appelle la transformation de Tseitin et le solveur (utilisant par défaut les Watched-Literals avec l'heuristique MOMS). Cela fait, on retourne le graphe colorié en calculant les couleurs à partir des variables de la formule.
Pour les couleurs, on utilise le format Teinte-Saturation-Valeur avec une teinte répartie régulièrement entre 0 et 1 (la couleur 0 a pour teinte 0 et la couleur k-1 la teinte 1) et une saturation-valeur fixée astucieusement.
Si le graphe n'est pas k-coloriable alors il reste coloré en blanc.
Attention, si k devient grand (dès 5 ou 6) quelques couleurs peuvent se ressembler. Ne pas hésiter à regarder la source du graphe au format dot/graphviz pour lever les ambiguïtés.

Exemple d'utilisation du coloriage de graphe :
On cherche un 5-coloriage du graphe contenu dans le fichier test.col et on place la sortie au format dot/graphviz dans test.dot.
    ./colorie 5 test.col > test.dot
On affiche la sortie dans un fichier pdf (nécessite Graphviz, d'autre formats comme png ou svg sont supportés) :
    dot test.dot -Tpdf > test.pdf

Pour la corbeille d'expériences, se référer à experiences/experiences.fm

Concernant la répartition des tâches, Marc à écrit la structure de données pour les formules booléennes, la transformation de Tseitin et les générateurs ainsi que conduit les tests (scripts + commentaires) pendant que Thomas a créé le parser de formules logiques et le système de coloriage (parser, conversion et sortie) et la création du présent menu. Enfin, le travail sur les heuristiques à été fait à deux.



=== Rendu 1 ===
Oyez, oyez ! Tant de nouveautés !

Bon, il s'agit du premier rendu implémentant DPLL et les Watched Literals. Trêve de trivialités, maintenant, détaillons.

En tout premier lieu, la structure de donnée. On a repris le code du DM de Chevalier pour ça. Aussi, on a gardé la structure en couche successive de Formule->Clause->Littéral->Variable utilisant le conteneur d'ensemble non ordonné de la STL du C++11. Certaines classes ont été enrichies dans leur fonctionnement. Par exemple, on a ajouter des types énumérations pour décrire le résultat d'une évaluation : faux, vrai, inconnu. De la même façon, on a une type pour la polarité : positif, négatif, absent ou tautologie (présence des deux). Cependant, une classe a été largement allégée : la classe Formule. En effet, on a déplacé le parser et le solveur vers des classes indépendantes. Aussi, on a une classe (abstraite) dont hérite tous les solveurs : Davis-Putnamm et les solveurs DPLL. Pour ces derniers, on a une classe abstraite dont hérite le solveur DPLL simple et le DPLL avec la technique des Watched Literals. D'autre part, le backtracking se gère avec des lancés et gestions
d'exception. D'où la déclaration de plusieurs exceptions.

Voilà pour la structure. Suite !

Du point de vue algorithmique... On a recyclé pas mal d'optimisation du Davis-Putnamm. Chaque décision sur la valeur d'une variable induit un certain nombre de propagations unitaires et d'éliminations de littéraux purs qui sont réalisés en boucle, jusqu'à point fixe. Lors de ce procédé, on supprime les clauses qui sont satisfaites (même si leur évaluation renvoie la valeur énumérée "inconnue" car toutes les variables ne sont pas encore assignées) et les littéraux qui sont assignés à false.
Après ces simplification, on procède à la détection des clauses qui sont des surclauses d'une autre clause de la formule et on les supprime.

Un point intéressant est la gestion du backtracking. Le principe est simple : on décide, on explore, si on obtient une contradiction on lance une exception, on remonte et on teste l'autre assignation, sinon on termine et la formule contient son assignation. Pour cela il a fallut écrire un constructeur de copie pour les formules. J'attire votre attention là-dessus car, à cause de la structure de donnée, c'est loin d'être trivial. Il faut, en particulier, prendre soin de créer de nouvelles variables et de nouveaux littéraux. Ensuite, il faut entièrement reconstruire les clauses en fonction des identifiants des variables.

Pour les Watched-Literals, on a implémenté simplement la méthode proposé dans les transparents. La seule optimisation ajoutée a été de supprimer dans la formule courante les clauses dont on vu qu'un littéral est à vrai et de supprimer les littéraux faux des clauses quand on les rencontres (notamment dans la recherche de nouveaux littéraux à surveiller). Cela permet de réduire le nombre d'itérations lors de simplifications suivantes.

On a aussi essayé d'utiliser plus à fond les méthode de la STL, pour gagner du temps. Mais il y a sans doute encore des pistes d'amélioration de ce côté, afin d'éviter des boucles inutiles. La seconde piste d'amélioration serait de faire en sorte de limiter au maximum le coût des copies de formules causés par le système de backtracking. Enfin, une destruction fine de la mémoire inutile (clauses qui ne servirons plus...) au cours de l'algorithme permettrait de diminuer la consommation mémoire.


En ce qui concerne l'interface... Il suffit de passer des arguments en ligne de commande. Il y a bien sûr -wl qui active une résolution avec DPLL avec les Watched Literals. L'argument -dp procède à la résolution avec Davis-Putnamm. Bien sûr, ne donner aucun argument lance un DPLL simple. Il y a aussi une version avec des sorties de débuggage. La chose se fait à la compilation. Il suffit de compiler avec la commande :
make debug
La compilation donnant le programme sans les sorties de débuggages se fait toujours avec la commande :
make
On signale l'existence de :
make clean
pour supprimer tous les .o générés à la compilation. Il a été choisi de faire ce réglage à la compilation (via des directives de préprocesseur) pour pas perdre son temps en test lors de l'exécution pour une chose aussi futile que l'affichage...
Attention : pour passer du mode debug au mode normal un "make clean" est nécessaire afin de purger le cache du système de build.




Il convient de signaler que le générateur à exemple a été refait, l'interface est la même mais le fonctionnement a complètement changé. Et ce, dans un seul but : ne pas générer de tautologies. En effet, la probabilité de générer des tautologie quand la longueur des clauses s'approche du nombre de variables explose. Aussi, pour tester la méthode de résolution avec les Watched Literals, il est intéressant d'avoir de longues clauses qui ne sont pas des tautologies.




Maintenant, des chronométrages (DPLL vs WL):

ex1 : 0.01s / 0.02s
ex2 : 0.01s / 0.02s
ex3 : <0.01s / 0.01s
ex4 : <0.01s / 0.02s
ex5 : <0.01s / <0.01s

Nb de variables, nb de clauses, longueur min et max des clauses (DPLL vs WL). On teste avec de longues clauses pour laisser toutes ses chances aux Watched Literals.

50 4096 40 45 : 0.67s /  0.2s
100 4096 80 95 : 2.54s / 0.57s
200 4096 80 95 : 7.2s / 0.85s
400 4096 80 95 : 11.5s / 1.3s
800 4096 80 95 : 18.5s / 2.4s



200 2048 180 195 : 6.8s / 0.9s
200 4096 180 195 : 8.53s / 2.04s
200 8192 180 195 : 25.6s / 3.9s
200 16384 180 195 : 47.2s / 5.41s

400 2048 380 395 : 24.5s / 3.3s
400 4096 380 395 : 51.43s / 7.0s
400 8192 380 395 : 73.7s / 18.25s
400 16384 380 395 : 194.2s / 29.3s



400 8192 40 45 : 10.7s / 1.3s
400 8192 80 95 : 23.7s / 2.7s
400 8192 180 195 : 47.4s / 6.1s
400 8192 280 295 : 66.1s / 10.6s
400 8192 380 395 : 103.2s / 14.5s




On remarque que :
- Le nombre de variables n'a pas une grande influence (mais clairement non négligeable)
- L'efficacité des Watched Literals ne se voit qu'avec de longues clauses (mais on comprend pourquoi c'est breveté !).
- La longueur des clauses à une influence importante
- Tout comme le nombre de clauses.



On remarque aussi que le parser est lent... très lent ! En fait, le programme passe la majorité de son temps à parser et les temps donnés ci-dessus sont les temps effectifs d'exécution de l'algorithme.


Enfin, voici la répartition des tâches. Marc s'est chargé de maintenir la structure de données, de la "sortie" de l'algorithme de Davis-Putnam en "standalone", du système de simplification de formules utilisé par DPLL (méthode Formule.simplifier), du générateur de tests ainsi que du présent rapport. Thomas a lui écrit la boucle centrale de DPLL, les Watched-Literals, le main et le parser de fichiers *.cnf. Enfin, tout deux se sont arracher les cheveux à debugger.
